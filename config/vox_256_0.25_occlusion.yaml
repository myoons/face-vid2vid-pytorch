dataset_params:
  root_dir: data/vox_256
  frame_shape: [256, 256, 3]

model_params:
  common_params:
    depth: 16
    num_kp: 20
    num_channels: 3
  appearance_feature_extractor:
    block_expansion: 64
    res_block_features: 32
    num_down_blocks: 2
    num_res_blocks: 6
  canonical_keypoint_detector:
    block_expansion: 64
    max_features: 1024
    num_blocks: 5
    temperature: 0.1
    scale_factor: 0.25
    estimate_jacobian: False
  head_expression_estimator:
    block_expansion: 256
    num_bins: 66
    num_layers: [3, 3, 5, 2]
  occlusion_aware_generator:
    output_channels: 3
    block_expansion: 64
    source_channels: 32
    num_res_blocks: 6
    num_up_blocks: 2
    estimate_occlusion_map: True
    motion_field_estimator:
      block_expansion: 64
      num_blocks: 5
      max_features: 1024
      compress_channels: 4
      scale_factor: 0.25
      kp_variance: 0.01
  multi_scale_discriminator:
    scales: [1]
    block_expansion: 64
    max_features: 512
    negative: 0.2
    num_blocks: 5

train_params:
  num_epochs: 500
  num_repeats: 1
  num_bins: 66
  keypoint_distance_threshold: 0.1
  keypoint_depth_target: 0.33
  epoch_milestones: [60, 90]
  lr_appearance_feature_extractor: 2.0e-4
  lr_canonical_keypoint_detector: 2.0e-4
  lr_head_expression_estimator: 2.0e-4
  lr_occlusion_aware_generator: 2.0e-4
  lr_multi_scale_discriminator: 2.0e-4
  pretrained_hopenet_dir: pretrained/hopenet.pkl
  batch_size: 8
  scales: [1, 0.5, 0.25, 0.125]
  checkpoint_freq: 50
  transform_params:
    sigma_affine: 0.05
    # sigma_tps: 0.005
    # points_tps: 5
  loss_weights:
    perceptual: 10
    generator_gan: 1
    discriminator_gan: 1
    feature_matching: 10
    equivariance_keypoints: 20
    equivariance_jacobian: 20
    keypoint_prior: 10
    head_pose: 20
    deformation_prior: 5
    perceptual_layers: [0.03125, 0.0625, 0.125, 0.25, 1.0]


visualizer_params:
  kp_size: 3
  draw_border: True
  colormap: 'gist_rainbow'